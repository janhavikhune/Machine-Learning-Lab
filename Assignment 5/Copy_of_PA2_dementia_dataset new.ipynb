{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l5JIHknZnEI"
   },
   "source": [
    "Classify if Demented, Nondemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Gxrjty74oSAl"
   },
   "outputs": [],
   "source": [
    "#set up a ColumnTransformer with StandardScaler for numerical features and OneHotEncoder for categorical features.\n",
    "#set up and training a LinearRegression model using scikit-learn, including data preprocessing steps within a Pipeline.\n",
    "#implement polynomial regression\n",
    "#perform hyperparameter tuning for a polynomial regression model\n",
    "#evaluate the performance of a regression model on test data\n",
    "#use OneHotEncoder with handle_unknown='ignore' within a preprocessing pipeline to handle unseen categories during model training and evaluation\n",
    "#set up and execute cross_val_score or GridSearchCV to perform cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfzAeQZVwSZq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "MSE: 0.551304620677184\n",
      "R²: 0.579288123149722\n",
      "\n",
      "Best polynomial degree: 1\n",
      "Polynomial Regression Results:\n",
      "MSE: 0.551304620677184\n",
      "R²: 0.579288123149722\n",
      "\n",
      "Cross-validation R² scores: [0.54889665 0.47208401 0.55769937 0.52896402 0.65483872]\n",
      "Mean CV R²: 0.5524965533254478\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "\n",
    "df['Region'] = pd.cut(df['Latitude'], bins=3, labels=['North', 'Central', 'South'])\n",
    "\n",
    "# 2. Feature separation\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# 3. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Define columns\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int']).columns.tolist()\n",
    "categorical_cols = ['Region']\n",
    "\n",
    "# 5. Preprocessor with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6. Pipeline: Linear Regression\n",
    "linear_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# 7. Fit Linear Regression\n",
    "linear_pipeline.fit(X_train, y_train)\n",
    "y_pred = linear_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# 8. Polynomial Regression with pipeline\n",
    "poly_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# 9. Grid Search for best polynomial degree\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(poly_pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest polynomial degree:\", grid_search.best_params_['poly__degree'])\n",
    "\n",
    "# 10. Evaluation on test data using best model\n",
    "best_poly_model = grid_search.best_estimator_\n",
    "y_poly_pred = best_poly_model.predict(X_test)\n",
    "\n",
    "print(\"Polynomial Regression Results:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_poly_pred))\n",
    "print(\"R²:\", r2_score(y_test, y_poly_pred))\n",
    "\n",
    "# 11. Cross-validation scores\n",
    "cv_scores = cross_val_score(best_poly_model, X, y, cv=5, scoring='r2')\n",
    "print(\"\\nCross-validation R² scores:\", cv_scores)\n",
    "print(\"Mean CV R²:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJ66eKWt31A8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best polynomial degree: 1\n",
      "Best score from CV: 0.5754706814791134\n",
      "Test R^2 Score: 0.6203531973214178\n",
      "Test MSE: 5.821250974404927\n",
      "\n",
      "Scores for each degree:\n",
      "Degree 1: R² = 0.5755\n",
      "Degree 2: R² = 0.5068\n",
      "Degree 3: R² = 0.3723\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\shubham\\OneDrive\\Desktop\\j\\dementia.csv')\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=['MMSE'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('MMSE', axis=1)\n",
    "y = df['MMSE']\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_cols = X.select_dtypes(include=[float, int]).columns\n",
    "\n",
    "# Fill missing values in numeric columns with the mean\n",
    "X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Impute missing numerical values\n",
    "        ('scaler', StandardScaler())  # Scale the numerical features\n",
    "    ]), numerical_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical values\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One hot encode categorical features\n",
    "    ]), categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3] \n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='r2', n_jobs=-1)  \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(\"Best polynomial degree:\", grid_search.best_params_['poly__degree'])\n",
    "print(\"Best score from CV:\", grid_search.best_score_)\n",
    "print(\"Test R^2 Score:\", r2_score(y_test, y_pred))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "cv_scores = grid_search.cv_results_['mean_test_score']\n",
    "degrees = param_grid['poly__degree']\n",
    "print(\"\\nScores for each degree:\")\n",
    "for degree, score in zip(degrees, cv_scores):\n",
    "    print(f\"Degree {degree}: R² = {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-KNKPtB6scR"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RneJiWHD89Ho"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTysq37D-9Lk"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pXKe9uLZekN"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1YaHlKw0U_mzp4KTszVUd8lLtEwqCq-6v",
     "timestamp": 1742190086510
    },
    {
     "file_id": "1066dqyy8Tml6_HaO7WUSgW1j7b0tsVWy",
     "timestamp": 1713935971369
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
